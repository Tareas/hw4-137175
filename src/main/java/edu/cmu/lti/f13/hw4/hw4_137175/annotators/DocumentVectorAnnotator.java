package edu.cmu.lti.f13.hw4.hw4_137175.annotators;

import java.io.StreamTokenizer;
import java.io.StringReader;
import java.util.Vector;

import org.apache.uima.analysis_component.JCasAnnotator_ImplBase;
import org.apache.uima.analysis_engine.AnalysisEngineProcessException;
import org.apache.uima.cas.FSIterator;
import org.apache.uima.jcas.JCas;
import org.apache.uima.jcas.cas.IntegerArray;
import org.apache.uima.jcas.cas.StringArray;
import org.apache.uima.jcas.tcas.Annotation;

import edu.cmu.lti.f13.hw4.hw4_137175.typesystems.Document;

public class DocumentVectorAnnotator extends JCasAnnotator_ImplBase {

	@Override
	public void process(JCas jcas) throws AnalysisEngineProcessException {

		FSIterator<Annotation> iter = jcas.getAnnotationIndex().iterator();
		if (iter.isValid()) {
			iter.moveToNext();
			Document doc = (Document) iter.get();
			createTermFreqVector(jcas, doc);
		}

	}
	/**
	 * 
	 * @param jcas
	 * @param doc
	 */

	private void createTermFreqVector(JCas jcas, Document doc) {

		String docText = doc.getText();
		
		//TO DO: construct a vector of tokens and update the tokenList in CAS
		
		  Vector<StreamTokenizer> tokens = new Vector<StreamTokenizer>();
		  StreamTokenizer token = new StreamTokenizer(new StringReader(docText)); 
		  
		  if(docText.length()!= 0){
			  tokens.addElement(token);
			 }else{
				 System.out.println("There are no more tokens!");
				 
			}
		  }		

	}
